{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (CF) \n",
    "\n",
    "It is a mean of recommendation based on usersâ€™ past behavior. There are two categories of CF:\n",
    "\n",
    "User-based: measure the similarity between target users and other users\n",
    "\n",
    "Item-based: measure the similarity between the items that target users rates/ interacts with and other items\n",
    "\n",
    "The key idea behind CF is that similar users share the same interest and that similar items are liked by a user.\n",
    "\n",
    "![user_item_cf](images/user_item_cf.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE of training of model is a metric which measure how much the signal and the noise is explained by the model. I noticed that my RMSE is quite big. I suppose I might have overfitted the training data.\n",
    "\n",
    "Overall, Memory-based Collaborative Filtering is easy to implement and produce reasonable prediction quality. However, there are some drawback of this approach:\n",
    "\n",
    "It doesn't address the well-known cold-start problem, that is when new user or new item enters the system.\n",
    "It can't deal with sparse data, meaning it's hard to find users that have rated the same items.\n",
    "It suffers when new users or items that don't have any ratings enter the system.\n",
    "It tends to recommend popular items.\n",
    "\n",
    "Load dataset from the ratings, only need the following info: user, movie, rate\n",
    "\n",
    "    [('186', '302', '3'),\n",
    "     ('22', '377', '1'),\n",
    "     ('244', '51', '2'),\n",
    "     ('166', '346', '1'),\n",
    "     ('298', '474', '4'),\n",
    "     ('115', '265', '2'),\n",
    "     ('253', '465', '5'),\n",
    "     ('305', '451', '3'),\n",
    "     ('6', '86', '3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and paring input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "BuiltinDataset = namedtuple('BuiltinDataset', ['url', 'path', 'sep', 'reader_params'])\n",
    "\n",
    "BUILTIN_DATASETS = {\n",
    "    'ml-100k':\n",
    "        BuiltinDataset(\n",
    "            url='http://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
    "            path='data/ml-100k/u.data',\n",
    "            sep='\\t',\n",
    "            reader_params=dict(line_format='user item rating timestamp',\n",
    "                               rating_scale=(1, 5),\n",
    "                               sep='\\t')\n",
    "        ),\n",
    "    'ml-100k-movie':\n",
    "        BuiltinDataset(\n",
    "            url='http://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
    "            path='data/ml-100k/u.item',\n",
    "            sep='|',\n",
    "            reader_params=dict(line_format='user item rating timestamp',\n",
    "                               rating_scale=(1, 5),\n",
    "                               sep='\\t')\n",
    "        ),\n",
    "    'ml-1m'  :\n",
    "        BuiltinDataset(\n",
    "            url='http://files.grouplens.org/datasets/movielens/ml-1m.zip',\n",
    "            path='data/ml-1m/ratings.dat',\n",
    "            sep='::',\n",
    "            reader_params=dict(line_format='user item rating timestamp',\n",
    "                               rating_scale=(1, 5),\n",
    "                               sep='::')\n",
    "        ),\n",
    "}\n",
    "\n",
    "# modify the random seed will change dataset spilt.\n",
    "# if you want to use the model saved before, please don't modify this seed.\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "class DataSet:\n",
    "    \"\"\"Base class for loading datasets.\n",
    "\n",
    "    Note that you should never instantiate the :class:`Dataset` class directly\n",
    "    (same goes for its derived classes), but instead use one of the below\n",
    "    available methods for loading datasets.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset(cls, name='ml-100k'):\n",
    "        \"\"\"Load a built-in dataset.\n",
    "\n",
    "        :param name:string: The name of the built-in dataset to load.\n",
    "                Accepted values are 'ml-100k', 'ml-1m', and 'jester'.\n",
    "                Default is 'ml-100k'.\n",
    "        :return: ratings for each line.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dataset = BUILTIN_DATASETS[name]\n",
    "        except KeyError:\n",
    "            raise ValueError('unknown dataset ' + name +\n",
    "                             '. Accepted values are ' +\n",
    "                             ', '.join(BUILTIN_DATASETS.keys()) + '.')\n",
    "        if not os.path.isfile(dataset.path):\n",
    "            raise OSError(\n",
    "                \"Dataset data/\" + name + \" could not be found in this project.\\n\"\n",
    "                                         \"Please download it from \" + dataset.url +\n",
    "                ' manually and unzip it to data/ directory.')\n",
    "        print('Loading dataset file %s' % dataset.path)\n",
    "        with open(dataset.path, encoding = \"ISO-8859-1\") as f:\n",
    "            ratings = [cls.parse_line(line, dataset.sep) for line in itertools.islice(f, 0, None)]\n",
    "        print(\"Load \" + name + \" dataset success.\")\n",
    "        return ratings\n",
    "\n",
    "    @classmethod\n",
    "    def parse_line(cls, line: str, sep: str):\n",
    "        \"\"\"\n",
    "        Parse a line.\n",
    "\n",
    "        Ratings as ensured to positive integers.\n",
    "\n",
    "        the separator in rating.data is `::`.\n",
    "\n",
    "        :param sep: the separator between fields. Example : ``';'``.\n",
    "        :param line: The line to parse\n",
    "\n",
    "        :return: tuple: User id, item id, rating score.\n",
    "                The timestamp will be ignored cause it wasn't used in Collaborative filtering.\n",
    "        \"\"\"\n",
    "        user, movie, rate = line.strip('\\r\\n').split(sep)[:3]\n",
    "        return user, movie, rate\n",
    "\n",
    "    @classmethod\n",
    "    def train_test_split(cls, ratings, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split rating data to training set and test set.\n",
    "\n",
    "        The default `test_size` is the test percentage of test size.\n",
    "\n",
    "        The rating file should be a instance of DataSet.\n",
    "\n",
    "        :param ratings: raw dataset\n",
    "        :param test_size: the percentage of test size.\n",
    "        :return: train_set and test_set\n",
    "        \"\"\"\n",
    "        train, test = collections.defaultdict(dict), collections.defaultdict(dict)\n",
    "        trainset_len = 0\n",
    "        testset_len = 0\n",
    "        for user, movie, rate in ratings:\n",
    "            if random.random() <= test_size:\n",
    "                test[user][movie] = int(rate)\n",
    "                testset_len += 1\n",
    "            else:\n",
    "                train[user][movie] = int(rate)\n",
    "                trainset_len += 1\n",
    "        print('split rating data to training set and test set success.')\n",
    "        print('train set size = %s' % trainset_len)\n",
    "        print('test set size = %s\\n' % testset_len)\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Manager will save and load the trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class ModelManager:\n",
    "    \"\"\"\n",
    "    Model manager is designed to load and save all models.\n",
    "    No matter what dataset name.\n",
    "    \"\"\"\n",
    "    # This dataset_name belongs to the whole class.\n",
    "    # So it should be init for only once.\n",
    "    path_name = ''\n",
    "\n",
    "    @classmethod\n",
    "    def __init__(cls, dataset_name=None, test_size=0.3):\n",
    "        \"\"\"\n",
    "        cls.dataset_name should only init for only once.\n",
    "        :param dataset_name:\n",
    "        \"\"\"\n",
    "        if not cls.path_name:\n",
    "            cls.path_name = \"model/\" + dataset_name + '-testsize' + str(test_size)\n",
    "\n",
    "    def save_model(self, model, save_name: str):\n",
    "        \"\"\"\n",
    "        Save model to model/ dir.\n",
    "        :param model: source model\n",
    "        :param save_name: model saved name.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if 'pkl' not in save_name:\n",
    "            save_name += '.pkl'\n",
    "        if not os.path.exists('model'):\n",
    "            os.mkdir('model')\n",
    "        pickle.dump(model, open(self.path_name + \"-%s\" % save_name, \"wb\"))\n",
    "\n",
    "    def load_model(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Load model from model/ dir via model name.\n",
    "        :param model_name:\n",
    "        :return: loaded model\n",
    "        \"\"\"\n",
    "        if 'pkl' not in model_name:\n",
    "            model_name += '.pkl'\n",
    "        if not os.path.exists(self.path_name + \"-%s\" % model_name):\n",
    "            raise OSError('There is no model named %s in model/ dir' % model_name)\n",
    "        else:\n",
    "            print('Load model from %s \\n' % self.path_name)\n",
    "        return pickle.load(open(self.path_name + \"-%s\" % model_name, \"rb\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_workspace(clean=False):\n",
    "        \"\"\"\n",
    "        Clean the whole workspace.\n",
    "        All File in model/ dir will be removed.\n",
    "        :param clean: Boolean. Clean workspace or not.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if clean and os.path.exists('model'):\n",
    "            shutil.rmtree('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the similarity \n",
    "\n",
    "Based on user's WH, to calculate the similarity. \n",
    "    let's say user 1 watched movies: 1, 2, 3, 4, 5\n",
    "              user 2 watched movies: 1, 3, 5\n",
    "              \n",
    "    The similarity score between user1 and user2 will be 3, and considering iif, as following\n",
    "    \n",
    "    Calculate user similarity matrix by building movie-users inverse table.\n",
    "    \n",
    "    The calculating will only between users which have common items votes.\n",
    "    :param use_iif_similarity:  \n",
    "    \n",
    "    This is based on User User IIF similarity index - Google Search, same reason as TF-IDF\n",
    "                                if the item is very popular, users' similarity will be lower.\n",
    "    :param trainset: trainset\n",
    "    :return: similarity matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_user_similarity(trainset, use_iif_similarity=False):\n",
    "    # build inverse table for item-users\n",
    "    # key=movieID, value=list of userIDs who have seen this movie\n",
    "    print('building movie-users inverse table...')\n",
    "    movie2users = collections.defaultdict(set)\n",
    "    movie_popular = defaultdict(int)\n",
    "\n",
    "    for user, movies in trainset.items():\n",
    "        for movie in movies:\n",
    "            movie2users[movie].add(user)\n",
    "            movie_popular[movie] += 1\n",
    "    print('building movie-users inverse table success.')\n",
    "\n",
    "    # save the total movie number, which will be used in evaluation\n",
    "    movie_count = len(movie2users)\n",
    "    print('total movie number = %d' % movie_count)\n",
    "\n",
    "    # count co-rated items between users\n",
    "    print('generate user co-rated movies similarity matrix...')\n",
    "    # the keys of usersim_mat are user1's id,\n",
    "    # the values of usersim_mat are dicts which save {user2's id: co-occurrence times}.\n",
    "    # so you can seem usersim_mat as a two-dim table.\n",
    "    # TODO DO NOT USE DICT TO SAVE MATRIX, USE LIST INDEED.\n",
    "    # TODO IF USE LIST, THE MATRIX WILL BE VERY SPARSE.\n",
    "    usersim_mat = {}\n",
    "    # record the calculate time has spent.\n",
    "    for movie, users in movie2users.items():\n",
    "        for user1 in users:\n",
    "            # set default similarity between user1 and other users equals zero\n",
    "            usersim_mat.setdefault(user1, defaultdict(int))\n",
    "            for user2 in users:\n",
    "                if user1 == user2:\n",
    "                    continue\n",
    "                # ignore the score they voted.\n",
    "                # user similarity matrix only focus on co-occurrence.\n",
    "                if use_iif_similarity:\n",
    "                    # if the item is very popular, users' similarity will be lower.\n",
    "                    usersim_mat[user1][user2] += 1 / math.log(1 + len(users))\n",
    "                else:\n",
    "                    # origin method, users'similarity based on common items count.\n",
    "                    usersim_mat[user1][user2] += 1\n",
    "        # log steps and times.\n",
    "    print('generate user co-rated movies similarity matrix success.')\n",
    "\n",
    "    # calculate user-user similarity matrix\n",
    "    print('calculate user-user similarity matrix...')\n",
    "    # record the calculate time has spent.\n",
    "    for user1, related_users in usersim_mat.items():\n",
    "        len_user1 = len(trainset[user1])\n",
    "        for user2, count in related_users.items():\n",
    "            len_user2 = len(trainset[user2])\n",
    "            # The similarity of user1 and user2 is len(common movies)/sqrt(len(user1 movies)* len(user2 movies)\n",
    "            usersim_mat[user1][user2] = count / math.sqrt(len_user1 * len_user2)\n",
    "            # log steps and times.\n",
    "\n",
    "    print('calculate user-user similarity matrix success.')\n",
    "    return usersim_mat, movie_popular, movie_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend: UserCF model implementation\n",
    "\n",
    "The recommendation be as following steps:\n",
    "\n",
    "    1, find the top relevant users, based on similarity score\n",
    "    2, filtering out the watched movie by current user\n",
    "    3, predict the score for current user, based on relevant users,\n",
    "        predict_score[movie] += similarity_factor * rating\n",
    "    4, return the top ones, based on the predict_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from operator import itemgetter\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class UserBasedCF:\n",
    "    \"\"\"\n",
    "    User-based Collaborative filtering.\n",
    "    Top-N recommendation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k_sim_user=20, n_rec_movie=10, use_iif_similarity=False, save_model=True):\n",
    "        \"\"\"\n",
    "        Init UserBasedCF with n_sim_user and n_rec_movie.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        print(\"UserBasedCF start...\\n\")\n",
    "        self.k_sim_user = k_sim_user\n",
    "        self.n_rec_movie = n_rec_movie\n",
    "        self.trainset = None\n",
    "        self.save_model = save_model\n",
    "        self.use_iif_similarity = use_iif_similarity\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        \"\"\"\n",
    "        Fit the trainset by calculate user similarity matrix.\n",
    "        :param trainset: train dataset\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        model_manager = ModelManager()\n",
    "        try:\n",
    "            self.user_sim_mat = model_manager.load_model(\n",
    "                'user_sim_mat-iif' if self.use_iif_similarity else 'user_sim_mat')\n",
    "            self.movie_popular = model_manager.load_model('movie_popular')\n",
    "            self.movie_count = model_manager.load_model('movie_count')\n",
    "            self.trainset = model_manager.load_model('trainset')\n",
    "            print('User origin similarity model has saved before.\\nLoad model success...\\n')\n",
    "        except OSError:\n",
    "            print('No model saved before.\\nTrain a new model...')\n",
    "            self.user_sim_mat, self.movie_popular, self.movie_count = \\\n",
    "                calculate_user_similarity(trainset=trainset,\n",
    "                                                     use_iif_similarity=self.use_iif_similarity)\n",
    "            self.trainset = trainset\n",
    "            print('Train a new model success.')\n",
    "            if self.save_model:\n",
    "                model_manager.save_model(self.user_sim_mat,\n",
    "                                         'user_sim_mat-iif' if self.use_iif_similarity else 'user_sim_mat')\n",
    "                model_manager.save_model(self.movie_popular, 'movie_popular')\n",
    "                model_manager.save_model(self.movie_count, 'movie_count')\n",
    "            print('The new model has saved success.\\n')\n",
    "\n",
    "    def recommend(self, user):\n",
    "        \"\"\"\n",
    "        Find K similar users and recommend N movies for the user.\n",
    "        :param user: The user we recommend movies to.\n",
    "        :return: the N best score movies\n",
    "        \"\"\"\n",
    "        if not self.user_sim_mat or not self.n_rec_movie or \\\n",
    "                not self.trainset or not self.movie_popular or not self.movie_count:\n",
    "            raise NotImplementedError('UserCF has not init or fit method has not called yet.')\n",
    "        K = self.k_sim_user\n",
    "        N = self.n_rec_movie\n",
    "        predict_score = collections.defaultdict(int)\n",
    "        if user not in self.trainset:\n",
    "            print('The user (%s) not in trainset.' % user)\n",
    "            return\n",
    "        # print('Recommend movies to user start...')\n",
    "        watched_movies = self.trainset[user]\n",
    "        for similar_user, similarity_factor in sorted(self.user_sim_mat[user].items(),\n",
    "                                                      key=itemgetter(1), reverse=True)[0:K]:\n",
    "            for movie, rating in self.trainset[similar_user].items():\n",
    "                if movie in watched_movies:\n",
    "                    continue\n",
    "                # predict the user's \"interest\" for each movie\n",
    "                # the predict_score is sum(similarity_factor * rating)\n",
    "                predict_score[movie] += similarity_factor * rating\n",
    "                # log steps and times.\n",
    "        # print('Recommend movies to user success.')\n",
    "        # return the N best score movies\n",
    "        return [movie for movie, _ in sorted(predict_score.items(), key=itemgetter(1), reverse=True)[0:N]]\n",
    "\n",
    "    def predict(self, testset):\n",
    "        \"\"\"\n",
    "        Recommend movies to all users in testset.\n",
    "        :param testset: test dataset\n",
    "        :return: `dict` : recommend list for each user.\n",
    "        \"\"\"\n",
    "        movies_recommend = defaultdict(list)\n",
    "        print('Predict scores start...')\n",
    "        # record the calculate time has spent.\n",
    "        for i, user in enumerate(testset):\n",
    "            rec_movies = self.recommend(user)  # type:list\n",
    "            movies_recommend[user].append(rec_movies)\n",
    "            # log steps and times.\n",
    "            predict_time.count_time()\n",
    "        print('Predict scores success.')\n",
    "        predict_time.finish()\n",
    "        return movies_recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ttrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset_name, test_size=0.3, clean=False):\n",
    "    print('*' * 70)\n",
    "    print('\\tThis is %s model trained on %s with test_size = %.2f' % ('UCF', dataset_name, test_size))\n",
    "    print('*' * 70 + '\\n')\n",
    "    model_manager = ModelManager(dataset_name, test_size)\n",
    "    try:\n",
    "        trainset = model_manager.load_model('trainset')\n",
    "        testset = model_manager.load_model('testset')\n",
    "    except OSError:\n",
    "        ratings = DataSet.load_dataset(name=dataset_name)\n",
    "        trainset, testset = DataSet.train_test_split(ratings, test_size=test_size)\n",
    "        model_manager.save_model(trainset, 'trainset')\n",
    "        model_manager.save_model(testset, 'testset')\n",
    "    '''Do you want to clean workspace and retrain model again?'''\n",
    "    '''if you want to change test_size or retrain model, please set clean_workspace True'''\n",
    "    model_manager.clean_workspace(clean)\n",
    "    model.fit(trainset)\n",
    "    return model, trainset, testset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Prediction using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserBasedCF start...\n",
      "\n",
      "**********************************************************************\n",
      "\tThis is UCF model trained on ml-100k with test_size = 0.10\n",
      "**********************************************************************\n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "Load model from model/ml-100k-testsize0.1 \n",
      "\n",
      "User origin similarity model has saved before.\n",
      "Load model success...\n",
      "\n",
      "recommend for userid = 100, who has watched:\n",
      "('Wedding Singer, The (1998)', '13-Feb-1998')\n",
      "('Chasing Amy (1997)', '01-Jan-1997')\n",
      "('Hard Rain (1998)', '16-Jan-1998')\n",
      "('Gattaca (1997)', '01-Jan-1997')\n",
      "('Full Monty, The (1997)', '01-Jan-1997')\n",
      "('Phantoms (1998)', '01-Jan-1998')\n",
      "recommend for userid = 100, the following movies:\n",
      "(\"Devil's Advocate, The (1997)\", '01-Jan-1997')\n",
      "('Cop Land (1997)', '01-Jan-1997')\n",
      "('Saint, The (1997)', '14-Mar-1997')\n",
      "('Kiss the Girls (1997)', '01-Jan-1997')\n",
      "('Full Monty, The (1997)', '01-Jan-1997')\n",
      "('Edge, The (1997)', '26-Sep-1997')\n",
      "('In & Out (1997)', '19-Sep-1997')\n",
      "('Gattaca (1997)', '01-Jan-1997')\n",
      "('Murder at 1600 (1997)', '18-Apr-1997')\n",
      "(\"Ulee's Gold (1997)\", '01-Jan-1997')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recommend_test(model, user_list, trainset):\n",
    "    for user in user_list:\n",
    "        recommend = model.recommend(str(user))\n",
    "        print(\"recommend for userid = %s, who has watched:\" % user)\n",
    "        movie_dict = get_movie_dict()\n",
    "        for movie in trainset[str(user)]:\n",
    "            print(movie_dict[movie])\n",
    "        print(\"recommend for userid = %s, the following movies:\" % user)\n",
    "        for movie in recommend:\n",
    "            print(movie_dict[movie])\n",
    "        print()\n",
    "\n",
    "def get_movie_dict():\n",
    "    movie_dict = {movie[0]:movie[1:] for movie in movies}\n",
    "    return movie_dict\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    trainset = None\n",
    "    testset = None\n",
    "    dataset_name = 'ml-100k'\n",
    "    test_size = 0.1\n",
    "    model = UserBasedCF()\n",
    "    model, trainset, testset = train_model(model, dataset_name, test_size, False)\n",
    "    recommend_test(model, [100], testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
